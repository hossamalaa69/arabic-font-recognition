{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.morphology import binary_erosion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBorderColor(img):\n",
    "    \n",
    "    border = np.asarray(img[0,:])\n",
    "    border = np.concatenate((border, np.asarray(img[-1, :])))\n",
    "    border = np.concatenate((border, np.asarray(img[:, 0])))\n",
    "    border = np.concatenate((border, np.asarray(img[:, -1])))\n",
    "    return np.bincount(border).argmax()\n",
    "\n",
    "def pre_processing(img):\n",
    "    #img_blurred = cv2.medianBlur(img,5)\n",
    "    #img_binarized = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    _, img_binarized = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)    \n",
    "    if(getBorderColor(img_binarized) != 0):\n",
    "        img_binarized = cv2.bitwise_not(img_binarized) \n",
    "    #img_binarized = adaptiveThresh(img, t=15, div=8)\n",
    "    return img_binarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def showImage(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "    #print(getBorderColor(img))\n",
    "    #w, h = img.shape[:2]\n",
    "    #print(cv2.countNonZero(img)/(w*h) * 100)\n",
    "\n",
    "\n",
    "#arr = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "#getBorderColor(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeaturesHOG(img):\n",
    "   img = cv2.resize(img, (256, 128))\n",
    "   cell_size = (32, 32)  # h x w in pixels\n",
    "   block_size = (2, 2)  # h x w in cells\n",
    "   nbins = 9  # number of orientation bins\n",
    "   # winSize is the size of the image cropped to an multiple of the cell size\n",
    "   hog = cv2.HOGDescriptor(_winSize=(img.shape[1] // cell_size[1] * cell_size[1],\n",
    "                                    img.shape[0] // cell_size[0] * cell_size[0]),\n",
    "                            _blockSize=(block_size[1] * cell_size[1],\n",
    "                                        block_size[0] * cell_size[0]),\n",
    "                            _blockStride=(cell_size[1], cell_size[0]),\n",
    "                            _cellSize=(cell_size[1], cell_size[0]),\n",
    "                            _nbins=nbins)\n",
    "\n",
    "   hog_feats = hog.compute(img)\n",
    "   return hog_feats.flatten() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-61333caf1cca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# feature f1 (density of foreground (black) pixels.)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimg_height\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mimg_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# feature f1 (density of foreground (black) pixels.)\n",
    "\n",
    "img_height = X_train[0].shape[0]\n",
    "img_width = X_train[0].shape[1]\n",
    "f1 = []\n",
    "# Crop out the window and calculate f1 for each cell\n",
    "for r in range(img_width - 1, 8 - 1, -4):\n",
    "    foreground = []\n",
    "    for c in range(0, img_height, int(img_height / 20)):\n",
    "        window = X_train[0][c:c+int(img_height / 20)-1, r-8:r]\n",
    "        foreground.append(np.average(window == 255))\n",
    "    f1.append(np.sum(foreground))\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of transitions black/white between two consecutive cells.\n",
    "f2 = []\n",
    "for r in range(img_width - 1, WIDTH - 1, -STRID):\n",
    "    cells = []\n",
    "    #get the cells in each window\n",
    "    for c in range(0, img_height, HEIGHT):\n",
    "        cells.append(image[c:c+HEIGHT-1, r-WIDTH:r])\n",
    "    summtion = 0\n",
    "    for i in range(2,N):\n",
    "        bi = int(np.sum(cells[i] == 255) == 0)\n",
    "        b_i = int(np.sum(cells[i - 1] == 255) == 0)\n",
    "        summtion += np.abs(bi - b_i )\n",
    "    f2.append(summtion)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_of_mass(window):\n",
    "    # calculate moments of binary image\n",
    "    M = cv2.moments(window)\n",
    "    # calculate x,y coordinate of center\n",
    "    cX = int(M[\"m10\"] / (M[\"m00\"] + 1e-5))\n",
    "    cY = int(M[\"m01\"] / (M[\"m00\"] + 1e-5))\n",
    "    return cX,cY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f3 differenceâ€™s position of gravity centers of foreground pixels in two consecutive frame (current and previous) note c - c_prev\n",
    "f3 = []\n",
    "centers = []\n",
    "for r in range(img_width - 1, WIDTH - 1, -STRID):\n",
    "    centers.append(get_center_of_mass(image[:, r-WIDTH:r]))\n",
    "f3.append(np.sqrt(np.power(centers[0][0], 2) + np.power(centers[0][1], 2)))\n",
    "for i in range(1,len(centers)):\n",
    "    f3.append(np.sqrt(np.power(centers[i][0] - centers[i - 1][0],\n",
    "                       2) + np.power(centers[i][1] - centers[i - 1][1], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f4 normalized vertical position of the center of gravity of the foreground pixels in the whole frame with respect tothe lower baseline. c - c_prev\n",
    "f4 = []\n",
    "centers = []\n",
    "for r in range(img_width - 1, WIDTH - 1, -STRID):\n",
    "    centers.append(get_center_of_mass(image[:, r-WIDTH:r]))\n",
    "for i in range(0, len(centers)):\n",
    "    f4.append(np.power(centers[i][1] - lb, 2) / img_height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f5,f6 represent the density of foreground pixels over and under the lower baselines.\n",
    "f5 = []\n",
    "f6 = []\n",
    "print(lb)\n",
    "for r in range(img_width - 1, WIDTH - 1, -STRID):\n",
    "    f5.append(np.sum(image[0:lb-1, r-WIDTH:r] == 255) / (img_height * WIDTH))\n",
    "    f6.append(np.sum(image[lb:, r-WIDTH:r] == 255) / (img_height * WIDTH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = -1\n",
    "index = 0\n",
    "for c in range(0, img_height, HEIGHT):\n",
    "    if c >= lb:\n",
    "        k = c\n",
    "        break\n",
    "    index += 1\n",
    "\n",
    "f7 = []\n",
    "for r in range(img_width - 1, WIDTH - 1, -STRID):\n",
    "    cells = []\n",
    "    #get the cells in each window\n",
    "    for c in range(0, k, HEIGHT):\n",
    "        cells.append(image[c:c+HEIGHT-1, r-WIDTH:r])\n",
    "    summtion = 0\n",
    "    for i in range(2, len(cells)):\n",
    "        bi = int(np.sum(cells[i] == 255) == 0)\n",
    "        b_i = int(np.sum(cells[i - 1] == 255) == 0)\n",
    "        summtion += np.abs(bi - b_i)\n",
    "    f7.append(summtion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zone to which the gravity center of black pixels belongs (lower zone f8 = 3, middle zone f8 = 2, upper zone f8 = 1)\n",
    "f8 = []\n",
    "for r in range(img_width - 1, WIDTH - 1, -STRID):\n",
    "    center_y = get_center_of_mass(image[:, r-WIDTH:r])[1]\n",
    "    if center_y > lb:\n",
    "        f8.append(3)\n",
    "    elif center_y < lb and center_y > lu:\n",
    "        f8.append(2)\n",
    "    else:\n",
    "        f8.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleft-up: the number of background pixels that have neighbor black pixels in the two directions (left and up)\n",
    "#The same applies to f9, . . ., f14 in six directions left-up, up-right, right-down, down-left, vertical and horizontal.f15, . . ., f20\n",
    "f9 = []\n",
    "f10 = []\n",
    "f11 = []\n",
    "f12 = []\n",
    "f13 = []\n",
    "f14 = []\n",
    "for r in range(img_width - 1, WIDTH - 1, -STRID):\n",
    "    window = image[:, r-WIDTH:r]\n",
    "    k1 = np.array([\n",
    "        [0, 1, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 0, 1],\n",
    "        [0, 1, 1],\n",
    "        [1, 1, 0]\n",
    "    ])\n",
    "    \n",
    "    f9.append(np.sum(binary_erosion(255 - window, k2) * binary_erosion(window, k1))/ img_height)\n",
    "    \n",
    "    k1 = np.array([\n",
    "        [0, 1, 0],\n",
    "        [0, 0, 1],\n",
    "        [0, 0, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [1, 0, 0],\n",
    "        [1, 1, 0],\n",
    "        [0, 1, 1]\n",
    "    ])    \n",
    "    f10.append(np.sum(binary_erosion(255 - window, k2) * binary_erosion(window, k1))/ img_height)\n",
    "    \n",
    "    \n",
    "    k1 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 1],\n",
    "        [0, 1, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 1, 1],\n",
    "        [1, 1, 0],\n",
    "        [1, 0, 0]\n",
    "    ])    \n",
    "    f11.append(np.sum(binary_erosion(255 - window, k2) * binary_erosion(window, k1))/ img_height)\n",
    "    \n",
    "    k1 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 1, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [1, 1, 0],\n",
    "        [0, 1, 1],\n",
    "        [0, 0, 1]\n",
    "    ])    \n",
    "    f12.append(np.sum(binary_erosion(255 - window, k2) *\n",
    "                      binary_erosion(window, k1)) / img_height)\n",
    "    \n",
    "    k1 = np.array([\n",
    "        [1, 0, 0],\n",
    "        [1, 0, 0],\n",
    "        [1, 0, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 1, 0],\n",
    "        [0, 1, 0],\n",
    "        [0, 1, 0]\n",
    "    ])    \n",
    "    f13.append(np.sum(binary_erosion(255 - window, k2) *\n",
    "                      binary_erosion(window, k1)) / img_height)\n",
    "    \n",
    "    k1 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 0],\n",
    "        [1, 1, 1]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [1, 1, 1],\n",
    "        [0, 0, 0]\n",
    "    ])    \n",
    "    f14.append(np.sum(binary_erosion(255 - window, k2) * binary_erosion(window, k1)) / img_height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleft-up: the number of background pixels that have neighbor black pixels in the two directions (left and up)\n",
    "#The same applies to f9, . . ., f14 in six directions left-up, up-right, right-down, down-left, vertical and horizontal.f15, . . ., f20\n",
    "f15 = []\n",
    "f16 = []\n",
    "f17 = []\n",
    "f18 = []\n",
    "f19 = []\n",
    "f20 = []\n",
    "for r in range(img_width - 1, WIDTH - 1, -STRID):\n",
    "    window = image[lu:lb, r-WIDTH:r]\n",
    "    k1 = np.array([\n",
    "        [0, 1, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 0, 1],\n",
    "        [0, 1, 1],\n",
    "        [1, 1, 0]\n",
    "    ])\n",
    "    \n",
    "    f15.append(np.sum(binary_erosion(255 - window, k2) * binary_erosion(window, k1))/ np.abs(lb-lu))\n",
    "    \n",
    "    k1 = np.array([\n",
    "        [0, 1, 0],\n",
    "        [0, 0, 1],\n",
    "        [0, 0, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [1, 0, 0],\n",
    "        [1, 1, 0],\n",
    "        [0, 1, 1]\n",
    "    ])    \n",
    "    f16.append(np.sum(binary_erosion(255 - window, k2) *\n",
    "                      binary_erosion(window, k1)) / np.abs(lb-lu))\n",
    "    \n",
    "    \n",
    "    k1 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 1],\n",
    "        [0, 1, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 1, 1],\n",
    "        [1, 1, 0],\n",
    "        [1, 0, 0]\n",
    "    ])    \n",
    "    f17.append(np.sum(binary_erosion(255 - window, k2) *\n",
    "                      binary_erosion(window, k1)) / np.abs(lb-lu))\n",
    "    \n",
    "    k1 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 1, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [1, 1, 0],\n",
    "        [0, 1, 1],\n",
    "        [0, 0, 1]\n",
    "    ])    \n",
    "    f18.append(np.sum(binary_erosion(255 - window, k2) *\n",
    "                      binary_erosion(window, k1)) / np.abs(lb-lu))\n",
    "    \n",
    "    k1 = np.array([\n",
    "        [1, 0, 0],\n",
    "        [1, 0, 0],\n",
    "        [1, 0, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 1, 0],\n",
    "        [0, 1, 0],\n",
    "        [0, 1, 0]\n",
    "    ])    \n",
    "    f19.append(np.sum(binary_erosion(255 - window, k2) *\n",
    "                      binary_erosion(window, k1)) / np.abs(lb-lu))\n",
    "    \n",
    "    k1 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 0],\n",
    "        [1, 1, 1]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [1, 1, 1],\n",
    "        [0, 0, 0]\n",
    "    ])    \n",
    "    f20.append(np.sum(binary_erosion(255 - window, k2) *\n",
    "                      binary_erosion(window, k1)) / np.abs(lb-lu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f21 = []\n",
    "f22 = []\n",
    "f23 = []\n",
    "f24 = []\n",
    "f25 = []\n",
    "f26 = []\n",
    "f27 = []\n",
    "f28 = []\n",
    "\n",
    "for r in range(img_width - 1, WIDTH - 1, -STRID):\n",
    "    window = image[lu:lb, r-WIDTH:r]\n",
    "    f21.append(np.sum(window[:, 0]) / img_height)\n",
    "    f22.append(np.sum(window[:, 1]) / img_height)\n",
    "    f23.append(np.sum(window[:, 2]) / img_height)\n",
    "    f24.append(np.sum(window[:, 3]) / img_height)\n",
    "    f25.append(np.sum(window[:, 4]) / img_height)\n",
    "    f26.append(np.sum(window[:, 5]) / img_height)\n",
    "    f27.append(np.sum(window[:, 6]) / img_height)\n",
    "    f28.append(np.sum(window[:, 7]) / img_height)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre processing of the image (baseline estimation)\n",
    "def baseline_estimatator(img):\n",
    "    horz_proj = np.sum(img, 1)\n",
    "    lb = np.argmax(horz_proj)\n",
    "    avg_row_density = np.mean(horz_proj)\n",
    "    lu = np.argmax(horz_proj >= avg_row_density)\n",
    "    return lb, lu\n",
    "\n",
    "\n",
    "def leftUp(img, height):\n",
    "    k1 = np.array([\n",
    "        [0, 1, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 0, 1],\n",
    "        [0, 1, 1],\n",
    "        [1, 1, 0]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def rightUp(img, height):\n",
    "    k1 = np.array([\n",
    "        [0, 1, 0],\n",
    "        [0, 0, 1],\n",
    "        [0, 0, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [1, 0, 0],\n",
    "        [1, 1, 0],\n",
    "        [0, 1, 1]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def rightDown(img, height):\n",
    "    k1 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 1],\n",
    "        [0, 1, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 1, 1],\n",
    "        [1, 1, 0],\n",
    "        [1, 0, 0]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def leftDown(img, height):\n",
    "    k1 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 1, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [1, 1, 0],\n",
    "        [0, 1, 1],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def vertical(img, height):\n",
    "    k1 = np.array([\n",
    "        [1, 0, 0],\n",
    "        [1, 0, 0],\n",
    "        [1, 0, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 1, 0],\n",
    "        [0, 1, 0],\n",
    "        [0, 1, 0]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def horizontal(img, height):\n",
    "    k1 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 0],\n",
    "        [1, 1, 1]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [1, 1, 1],\n",
    "        [0, 0, 0]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def get_center_of_mass(window):\n",
    "    # calculate moments of binary image\n",
    "    M = cv2.moments(window)\n",
    "    # calculate x,y coordinate of center\n",
    "    cX = int(M[\"m10\"] / (M[\"m00\"] + 1e-5))\n",
    "    cY = int(M[\"m01\"] / (M[\"m00\"] + 1e-5))\n",
    "    return cX, cY\n",
    "\n",
    "def getImageFeatures(img, WIDTH, HEIGHT, STRID, N, baseline):\n",
    "    lb, lu = baseline\n",
    "    img_height = img.shape[0]\n",
    "    img_width = img.shape[1]\n",
    "    X = []\n",
    "    centers = []\n",
    "    for r in range(img_width - 1, WIDTH - 1, -STRID):\n",
    "        window = img[:, r-WIDTH:r]\n",
    "        X_WINDOW = []\n",
    "        centers.append(get_center_of_mass(window))\n",
    "        X_WINDOW.append(np.sum(img[0:lb-1, r-WIDTH:r] == 255) / (img_height * WIDTH))\n",
    "        X_WINDOW.append(np.sum(img[lb:, r-WIDTH:r] == 255) /\n",
    "                  ((img_height - lb) * WIDTH))\n",
    "        X_WINDOW.append(np.sum(window == 255) / (WIDTH * img_height))\n",
    "        X_WINDOW.append(leftUp(window, img_height))\n",
    "        X_WINDOW.append(rightUp(window, img_height))\n",
    "        X_WINDOW.append(rightDown(window, img_height))\n",
    "        X_WINDOW.append(leftDown(window, img_height))\n",
    "        X_WINDOW.append(vertical(window, img_height))\n",
    "        X_WINDOW.append(horizontal(window, img_height))\n",
    "        window = img[lu:lb, r-WIDTH:r]\n",
    "        X_WINDOW.append(leftUp(window, np.abs(lb-lu)))\n",
    "        X_WINDOW.append(rightUp(window, np.abs(lb-lu)))\n",
    "        X_WINDOW.append(rightDown(window, np.abs(lb-lu)))\n",
    "        X_WINDOW.append(leftDown(window, np.abs(lb-lu)))\n",
    "        X_WINDOW.append(vertical(window, np.abs(lb-lu)))\n",
    "        X_WINDOW.append(horizontal(window, np.abs(lb-lu)))\n",
    "        window = img[lu:lb, r-WIDTH:r]\n",
    "        for w in range(WIDTH):\n",
    "            X_WINDOW.append(np.sum(window[:, w]) / img_height)\n",
    "        contours, _ = cv2.findContours(\n",
    "            window.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        X_WINDOW.append(len(contours))\n",
    "        X_WINDOW.append(np.average(cv2.Canny(window, 50, 200) == 255))\n",
    "        X.append(X_WINDOW)\n",
    "    X[0].append(centers[0][0])\n",
    "    X[0].append(centers[0][1])\n",
    "    for i in range(1, len(centers)):\n",
    "        X[i].append(centers[i][0] - centers[i - 1][0])\n",
    "        X[i].append(centers[i][1] - centers[i - 1][1])\n",
    "    for i in range(0, len(centers)):\n",
    "        X[i].append((centers[i][1] - lb) / img_height)\n",
    "    for inx, vec in enumerate(X):\n",
    "        X[inx] = np.array(vec)\n",
    "    return np.array(X, dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "\n",
    "def runs_of_ones_list(bits):\n",
    "    return np.array([sum(g) for b, g in groupby(bits) if b], dtype=object)\n",
    "print(runs_of_ones_list(X_train[0][40,:]).shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1348, 2)\n"
     ]
    }
   ],
   "source": [
    "data_set = []\n",
    "Y = []\n",
    "for i in range(1, 10):\n",
    "    for filename in os.listdir(\"ACdata_base/\" + str(i)):\n",
    "        img = cv2.imread(os.path.join(\"ACdata_base/\" + str(i),\n",
    "                                      filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            data_set.append(pre_processing(img))\n",
    "            Y.append(i)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    data_set, Y, test_size=0.2, random_state=85)\n",
    "\n",
    "\n",
    "def getFeatures28(images):\n",
    "    N = 20\n",
    "    WIDTH = 32 \n",
    "    STRID = 8\n",
    "    x_features = []\n",
    "    for i in range(len(images)):\n",
    "            img = images[i]\n",
    "            x_features.append((getImageFeatures(img, WIDTH, int(img.shape[0] / N), STRID, N, baseline_estimatator(img)), Y_train[i]))\n",
    "    return np.asarray(x_features, dtype=object)\n",
    "\n",
    "\n",
    "\n",
    "features28_training = getFeatures28(X_train)\n",
    "\n",
    "print(features28_training.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[] for _ in range(9)]\n",
    "for (mat, inx) in features28_training:\n",
    "    for vec in mat:\n",
    "        X[inx - 1].append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array(X[0])\n",
    "X2 = np.array(X[1])\n",
    "X3 = np.array(X[2])\n",
    "X4 = np.array(X[3])\n",
    "X5 = np.array(X[4])\n",
    "X6 = np.array(X[5])\n",
    "X7 = np.array(X[6])\n",
    "X8 = np.array(X[7])\n",
    "X9 = np.array(X[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"sample_42_X1.csv\", X[0], delimiter=\",\")\n",
    "# np.savetxt(\"sample_42_X2.csv\", X[1], delimiter=\",\")\n",
    "# np.savetxt(\"sample_42_X3.csv\", X[2], delimiter=\",\")\n",
    "# np.savetxt(\"sample_42_X4.csv\", X[3], delimiter=\",\")\n",
    "# np.savetxt(\"sample_42_X5.csv\", X[4], delimiter=\",\")\n",
    "# np.savetxt(\"sample_42_X6.csv\", X[5], delimiter=\",\")\n",
    "# np.savetxt(\"sample_42_X7.csv\", X[6], delimiter=\",\")\n",
    "# np.savetxt(\"sample_42_X8.csv\", X[7], delimiter=\",\")\n",
    "np.savetxt(\"sample_X1.csv\", X[0], delimiter=\",\")\n",
    "np.savetxt(\"sample_X2.csv\", X[1], delimiter=\",\")\n",
    "np.savetxt(\"sample_X3.csv\", X[2], delimiter=\",\")\n",
    "np.savetxt(\"sample_X4.csv\", X[3], delimiter=\",\")\n",
    "np.savetxt(\"sample_X5.csv\", X[4], delimiter=\",\")\n",
    "np.savetxt(\"sample_X6.csv\", X[5], delimiter=\",\")\n",
    "np.savetxt(\"sample_X7.csv\", X[6], delimiter=\",\")\n",
    "np.savetxt(\"sample_X8.csv\", X[7], delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    CLASSES = 9\n",
    "    def __init__(self):\n",
    "        self.models = [GaussianMixture(n_components=6, max_iter=200)\n",
    "                       for _ in range(Model.CLASSES)]\n",
    "    def fit(self, X, y):\n",
    "        self.models[y].fit(X)\n",
    "    def pridect(self, X):\n",
    "        label = None\n",
    "        global_likelihood = float('-inf')\n",
    "        for inx, model in enumerate(self.models):\n",
    "            local_likelihoods = model.score_samples(X)\n",
    "            temp_global_likelihood = sum(local_likelihoods)\n",
    "\n",
    "            if temp_global_likelihood > global_likelihood:\n",
    "                label = inx\n",
    "                global_likelihood = temp_global_likelihood\n",
    "        return label\n",
    "    def save(self):\n",
    "        for i in range(Model.CLASSES):\n",
    "            np.save('gmm_' + str(i) + '_weights', self.models[i].weights_, allow_pickle=False)\n",
    "            np.save('gmm_' + str(i) + '_means', self.models[i].means_, allow_pickle=False)\n",
    "            np.save('gmm_' + str(i) + '_covariances', self.models[i].covariances_, allow_pickle=False)\n",
    "    def reload(self):\n",
    "        self.models = []\n",
    "        for i in range(Model.CLASSES):\n",
    "            means = np.load('gmm_' + str(i) + '_means.npy')\n",
    "            covar = np.load('gmm_' + str(i) + '_covariances.npy')\n",
    "            loaded_gmm = GaussianMixture(\n",
    "                n_components=len(means), covariance_type='full')\n",
    "            loaded_gmm.precisions_cholesky_ = np.linalg.cholesky(np.linalg.inv(covar))\n",
    "            loaded_gmm.weights_ = np.load('gmm_' + str(i) + '_weights.npy')\n",
    "            loaded_gmm.means_ = means\n",
    "            loaded_gmm.covariances_ = covar\n",
    "            self.models.append(loaded_gmm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "M = Model()\n",
    "M.models = None\n",
    "M.reload()\n",
    "print(M.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Model()\n",
    "M.fit(X1, 0)\n",
    "M.fit(X2, 1)\n",
    "M.fit(X3, 2)\n",
    "M.fit(X4, 3)\n",
    "M.fit(X5, 4)\n",
    "M.fit(X6, 5)\n",
    "M.fit(X7, 6)\n",
    "M.fit(X8, 7)\n",
    "M.fit(X9, 8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "img = X_test[3]\n",
    "X_t = getImageFeatures(img, 32, int(\n",
    "    img.shape[0] / 20), 16, 20, baseline_estimatator(img))\n",
    "    \n",
    "print(Y_test[3])\n",
    "print(M.pridect(X_t) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.55192878338279\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ac = 0\n",
    "for inx, img in enumerate(X_train):\n",
    "    X_t = getImageFeatures(img, 32, int(\n",
    "        img.shape[0] / 20), 16, 20, baseline_estimatator(img))\n",
    "    if M.pridect(X_t) + 1 == Y_train[inx]:\n",
    "        ac +=1\n",
    "print(ac/len(Y_train) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.25222551928783\n"
     ]
    }
   ],
   "source": [
    "ac = 0\n",
    "for inx, img in enumerate(X_test):\n",
    "    X_t = getImageFeatures(img, 32, int(\n",
    "        img.shape[0] / 20), 16, 20, baseline_estimatator(img))\n",
    "    if M.pridect(X_t) + 1 == Y_test[inx]:\n",
    "        ac += 1\n",
    "print(ac/len(Y_test) * 100)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af19850de543c87aa9c5433cdfdc668182c4fce690f4a520383c35fe24f2761b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
