{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.morphology import binary_erosion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBorderColor(img):\n",
    "    \n",
    "    border = np.asarray(img[0,:])\n",
    "    border = np.concatenate((border, np.asarray(img[-1, :])))\n",
    "    border = np.concatenate((border, np.asarray(img[:, 0])))\n",
    "    border = np.concatenate((border, np.asarray(img[:, -1])))\n",
    "    return np.bincount(border).argmax()\n",
    "\n",
    "def pre_processing(img):\n",
    "    _, img_binarized = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)    \n",
    "    if(getBorderColor(img_binarized) != 0):\n",
    "        img_binarized = cv2.bitwise_not(img_binarized) \n",
    "    return img_binarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def showImage(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre processing of the image (baseline estimation)\n",
    "def baseline_estimatator(img):\n",
    "    horz_proj = np.sum(img, 1)\n",
    "    lb = np.argmax(horz_proj)\n",
    "    avg_row_density = np.mean(horz_proj)\n",
    "    lu = np.argmax(horz_proj >= avg_row_density)\n",
    "    return lb, lu\n",
    "\n",
    "\n",
    "def leftUp(img, height):\n",
    "    k1 = np.array([\n",
    "        [0, 1, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 0, 1],\n",
    "        [0, 1, 1],\n",
    "        [1, 1, 0]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def rightUp(img, height):\n",
    "    k1 = np.array([\n",
    "        [0, 1, 0],\n",
    "        [0, 0, 1],\n",
    "        [0, 0, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [1, 0, 0],\n",
    "        [1, 1, 0],\n",
    "        [0, 1, 1]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def rightDown(img, height):\n",
    "    k1 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 1],\n",
    "        [0, 1, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 1, 1],\n",
    "        [1, 1, 0],\n",
    "        [1, 0, 0]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def leftDown(img, height):\n",
    "    k1 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 1, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [1, 1, 0],\n",
    "        [0, 1, 1],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def vertical(img, height):\n",
    "    k1 = np.array([\n",
    "        [1, 0, 0],\n",
    "        [1, 0, 0],\n",
    "        [1, 0, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 1, 0],\n",
    "        [0, 1, 0],\n",
    "        [0, 1, 0]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def horizontal(img, height):\n",
    "    k1 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 0],\n",
    "        [1, 1, 1]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [1, 1, 1],\n",
    "        [0, 0, 0]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def get_center_of_mass(window):\n",
    "    # calculate moments of binary image\n",
    "    M = cv2.moments(window)\n",
    "    # calculate x,y coordinate of center\n",
    "    cX = int(M[\"m10\"] / (M[\"m00\"] + 1e-5))\n",
    "    cY = int(M[\"m01\"] / (M[\"m00\"] + 1e-5))\n",
    "    return cX, cY\n",
    "\n",
    "def getImageFeatures(img, WIDTH, HEIGHT, STRID, N, baseline):\n",
    "    lb, lu = baseline\n",
    "    img_height = img.shape[0]\n",
    "    img_width = img.shape[1]\n",
    "    X = []\n",
    "    centers = []\n",
    "    for r in range(img_width - 1, WIDTH - 1, -STRID):\n",
    "        window = img[:, r-WIDTH:r]\n",
    "        X_WINDOW = []\n",
    "        centers.append(get_center_of_mass(window))\n",
    "        X_WINDOW.append(np.sum(img[0:lb-1, r-WIDTH:r] == 255) / (img_height * WIDTH))\n",
    "        X_WINDOW.append(np.sum(img[lb:, r-WIDTH:r] == 255) /\n",
    "                  ((img_height - lb) * WIDTH))\n",
    "        X_WINDOW.append(np.sum(window == 255) / (WIDTH * img_height))\n",
    "        X_WINDOW.append(leftUp(window, img_height))\n",
    "        X_WINDOW.append(rightUp(window, img_height))\n",
    "        X_WINDOW.append(rightDown(window, img_height))\n",
    "        X_WINDOW.append(leftDown(window, img_height))\n",
    "        X_WINDOW.append(vertical(window, img_height))\n",
    "        X_WINDOW.append(horizontal(window, img_height))\n",
    "        window = img[lu:lb, r-WIDTH:r]\n",
    "        X_WINDOW.append(leftUp(window, np.abs(lb-lu)))\n",
    "        X_WINDOW.append(rightUp(window, np.abs(lb-lu)))\n",
    "        X_WINDOW.append(rightDown(window, np.abs(lb-lu)))\n",
    "        X_WINDOW.append(leftDown(window, np.abs(lb-lu)))\n",
    "        X_WINDOW.append(vertical(window, np.abs(lb-lu)))\n",
    "        X_WINDOW.append(horizontal(window, np.abs(lb-lu)))\n",
    "        window = img[lu:lb, r-WIDTH:r]\n",
    "        for w in range(WIDTH):\n",
    "            X_WINDOW.append(np.sum(window[:, w]) / img_height)\n",
    "        contours, _ = cv2.findContours(\n",
    "            window.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        X_WINDOW.append(len(contours))\n",
    "        X_WINDOW.append(np.average(cv2.Canny(window, 50, 200) == 255))\n",
    "        X.append(X_WINDOW)\n",
    "    X[0].append(centers[0][0])\n",
    "    X[0].append(centers[0][1])\n",
    "    for i in range(1, len(centers)):\n",
    "        X[i].append(centers[i][0] - centers[i - 1][0])\n",
    "        X[i].append(centers[i][1] - centers[i - 1][1])\n",
    "    for i in range(0, len(centers)):\n",
    "        X[i].append((centers[i][1] - lb) / img_height)\n",
    "    for inx, vec in enumerate(X):\n",
    "        X[inx] = np.array(vec)\n",
    "    return np.array(X, dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "\n",
    "def runs_of_ones_list(bits):\n",
    "    return np.array([sum(g) for b, g in groupby(bits) if b], dtype=object)\n",
    "print(runs_of_ones_list(X_train[0][40,:]).shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1348, 2)\n"
     ]
    }
   ],
   "source": [
    "data_set = []\n",
    "Y = []\n",
    "for i in range(1, 10):\n",
    "    for filename in os.listdir(\"ACdata_base/\" + str(i)):\n",
    "        img = cv2.imread(os.path.join(\"ACdata_base/\" + str(i),\n",
    "                                      filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            data_set.append(pre_processing(img))\n",
    "            Y.append(i)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    data_set, Y, test_size=0.2, random_state=85)\n",
    "\n",
    "\n",
    "def getFeatures28(images):\n",
    "    N = 20\n",
    "    WIDTH = 32 \n",
    "    STRID = 8\n",
    "    x_features = []\n",
    "    for i in range(len(images)):\n",
    "            img = images[i]\n",
    "            x_features.append((getImageFeatures(img, WIDTH, int(img.shape[0] / N), STRID, N, baseline_estimatator(img)), Y_train[i]))\n",
    "    return np.asarray(x_features, dtype=object)\n",
    "\n",
    "\n",
    "\n",
    "features28_training = getFeatures28(X_train)\n",
    "\n",
    "print(features28_training.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[] for _ in range(9)]\n",
    "for (mat, inx) in features28_training:\n",
    "    for vec in mat:\n",
    "        X[inx - 1].append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array(X[0])\n",
    "X2 = np.array(X[1])\n",
    "X3 = np.array(X[2])\n",
    "X4 = np.array(X[3])\n",
    "X5 = np.array(X[4])\n",
    "X6 = np.array(X[5])\n",
    "X7 = np.array(X[6])\n",
    "X8 = np.array(X[7])\n",
    "X9 = np.array(X[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    CLASSES = 9\n",
    "    def __init__(self):\n",
    "        self.models = [GaussianMixture(n_components=6, max_iter=200, random_state= 20)\n",
    "                       for _ in range(Model.CLASSES)]\n",
    "    def fit(self, X, y):\n",
    "        self.models[y].fit(X)\n",
    "    def pridect(self, X):\n",
    "        label = None\n",
    "        global_likelihood = float('-inf')\n",
    "        for inx, model in enumerate(self.models):\n",
    "            local_likelihoods = model.score_samples(X)\n",
    "            temp_global_likelihood = sum(local_likelihoods)\n",
    "\n",
    "            if temp_global_likelihood > global_likelihood:\n",
    "                label = inx\n",
    "                global_likelihood = temp_global_likelihood\n",
    "        return label\n",
    "    def save(self):\n",
    "        for i in range(Model.CLASSES):\n",
    "            np.save('gmm_' + str(i) + '_weights', self.models[i].weights_, allow_pickle=False)\n",
    "            np.save('gmm_' + str(i) + '_means', self.models[i].means_, allow_pickle=False)\n",
    "            np.save('gmm_' + str(i) + '_covariances', self.models[i].covariances_, allow_pickle=False)\n",
    "    def reload(self):\n",
    "        for i in range(Model.CLASSES):\n",
    "            means = np.load('gmm_' + str(i) + '_means.npy')\n",
    "            covar = np.load('gmm_' + str(i) + '_covariances.npy')\n",
    "            self.models[i].precisions_cholesky_ = np.linalg.cholesky(np.linalg.inv(covar))\n",
    "            self.models[i].weights_ = np.load('gmm_' + str(i) + '_weights.npy')\n",
    "            self.models[i].means_ = means\n",
    "            self.models[i].covariances_ = covar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2 = Model()\n",
    "M2.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Model()\n",
    "M.fit(X1, 0)\n",
    "M.fit(X2, 1)\n",
    "M.fit(X3, 2)\n",
    "M.fit(X4, 3)\n",
    "M.fit(X5, 4)\n",
    "M.fit(X6, 5)\n",
    "M.fit(X7, 6)\n",
    "M.fit(X8, 7)\n",
    "M.fit(X9, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.92284866468842\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ac = 0\n",
    "for inx, img in enumerate(X_train):\n",
    "    X_t = getImageFeatures(img, 32, int(\n",
    "        img.shape[0] / 20), 16, 20, baseline_estimatator(img))\n",
    "    if M.pridect(X_t) + 1 == Y_train[inx]:\n",
    "        ac +=1\n",
    "print(ac/len(Y_train) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = 0\n",
    "for inx, img in enumerate(X_test):\n",
    "    X_t = getImageFeatures(img, 32, int(\n",
    "        img.shape[0] / 20), 16, 20, baseline_estimatator(img))\n",
    "    if M.pridect(X_t) + 1 == Y_test[inx]:\n",
    "        ac += 1\n",
    "print(ac/len(Y_test) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "50  -> 94.3620178041543\n",
    "55  -> 94.06528189910979\n",
    "60  -> 94.65875370919882\n",
    "65  -> 94.65875370919882\n",
    "70  -> 94.95548961424333\n",
    "75  -> 94.95548961424333\n",
    "80  -> 92.87833827893175\n",
    "90  -> 93.76854599406528\n",
    "100 -> 94.95548961424333\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af19850de543c87aa9c5433cdfdc668182c4fce690f4a520383c35fe24f2761b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
