{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.morphology import binary_erosion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 5,
>>>>>>> 816822545e758cb8f576cf4ac1469b071af9e9c0
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def getBorderColor(img):\n",
    "    \n",
    "    border = np.asarray(img[0,:])\n",
    "    border = np.concatenate((border, np.asarray(img[-1, :])))\n",
    "    border = np.concatenate((border, np.asarray(img[:, 0])))\n",
    "    border = np.concatenate((border, np.asarray(img[:, -1])))\n",
    "    return np.bincount(border).argmax()\n",
    "\n",
    "def pre_processing(img):\n",
    "    _, img_binarized = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)    \n",
    "    if(getBorderColor(img_binarized) != 0):\n",
    "        img_binarized = cv2.bitwise_not(img_binarized) \n",
    "    return img_binarized"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def showImage(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "    #print(getBorderColor(img))\n",
    "    #w, h = img.shape[:2]\n",
    "    #print(cv2.countNonZero(img)/(w*h) * 100)\n",
    "\n",
    "\n",
    "#arr = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "#getBorderColor(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
=======
   "execution_count": 6,
>>>>>>> 816822545e758cb8f576cf4ac1469b071af9e9c0
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeaturesHOG(img):\n",
    "   img = cv2.resize(img, (256, 128))\n",
    "   cell_size = (32, 32)  # h x w in pixels\n",
    "   block_size = (2, 2)  # h x w in cells\n",
    "   nbins = 9  # number of orientation bins\n",
    "   # winSize is the size of the image cropped to an multiple of the cell size\n",
    "   hog = cv2.HOGDescriptor(_winSize=(img.shape[1] // cell_size[1] * cell_size[1],\n",
    "                                    img.shape[0] // cell_size[0] * cell_size[0]),\n",
    "                            _blockSize=(block_size[1] * cell_size[1],\n",
    "                                        block_size[0] * cell_size[0]),\n",
    "                            _blockStride=(cell_size[1], cell_size[0]),\n",
    "                            _cellSize=(cell_size[1], cell_size[0]),\n",
    "                            _nbins=nbins)\n",
    "\n",
    "   hog_feats = hog.compute(img)\n",
    "   return hog_feats.flatten() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_of_mass(window):\n",
    "    # calculate moments of binary image\n",
    "    M = cv2.moments(window)\n",
    "    # calculate x,y coordinate of center\n",
    "    cX = int(M[\"m10\"] / (M[\"m00\"] + 1e-5))\n",
    "    cY = int(M[\"m01\"] / (M[\"m00\"] + 1e-5))\n",
    "    return cX,cY\n",
    "\n",
<<<<<<< HEAD
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
=======
>>>>>>> 816822545e758cb8f576cf4ac1469b071af9e9c0
    "# pre processing of the image (baseline estimation)\n",
    "def baseline_estimatator(img):\n",
    "    horz_proj = np.sum(img, 1)\n",
    "    lb = np.argmax(horz_proj)\n",
    "    avg_row_density = np.mean(horz_proj)\n",
    "    lu = np.argmax(horz_proj >= avg_row_density)\n",
    "    return lb, lu\n",
    "\n",
    "\n",
    "def leftUp(img, height):\n",
    "    k1 = np.array([\n",
    "        [0, 1, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 0, 1],\n",
    "        [0, 1, 1],\n",
    "        [1, 1, 0]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def rightUp(img, height):\n",
    "    k1 = np.array([\n",
    "        [0, 1, 0],\n",
    "        [0, 0, 1],\n",
    "        [0, 0, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [1, 0, 0],\n",
    "        [1, 1, 0],\n",
    "        [0, 1, 1]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def rightDown(img, height):\n",
    "    k1 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 1],\n",
    "        [0, 1, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 1, 1],\n",
    "        [1, 1, 0],\n",
    "        [1, 0, 0]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def leftDown(img, height):\n",
    "    k1 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 1, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [1, 1, 0],\n",
    "        [0, 1, 1],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def vertical(img, height):\n",
    "    k1 = np.array([\n",
    "        [1, 0, 0],\n",
    "        [1, 0, 0],\n",
    "        [1, 0, 0]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 1, 0],\n",
    "        [0, 1, 0],\n",
    "        [0, 1, 0]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def horizontal(img, height):\n",
    "    k1 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 0],\n",
    "        [1, 1, 1]\n",
    "    ])\n",
    "    k2 = np.array([\n",
    "        [0, 0, 0],\n",
    "        [1, 1, 1],\n",
    "        [0, 0, 0]\n",
    "    ])\n",
    "    return np.sum(binary_erosion(255 - img, k2) * binary_erosion(img, k1))\n",
    "\n",
    "\n",
    "def get_center_of_mass(window):\n",
    "    # calculate moments of binary image\n",
    "    M = cv2.moments(window)\n",
    "    # calculate x,y coordinate of center\n",
    "    cX = int(M[\"m10\"] / (M[\"m00\"] + 1e-5))\n",
    "    cY = int(M[\"m01\"] / (M[\"m00\"] + 1e-5))\n",
    "    return cX, cY\n",
    "\n",
    "def getImageFeatures(img, WIDTH, HEIGHT, STRID, N, baseline):\n",
    "    lb, lu = baseline\n",
    "    img_height = img.shape[0]\n",
    "    img_width = img.shape[1]\n",
    "    X = []\n",
    "    centers = []\n",
    "    for r in range(img_width - 1, WIDTH - 1, -STRID):\n",
    "        window = img[:, r-WIDTH:r]\n",
    "        X_WINDOW = []\n",
    "        centers.append(get_center_of_mass(window))\n",
    "        X_WINDOW.append(np.sum(img[0:lb-1, r-WIDTH:r] == 255) / (img_height * WIDTH))\n",
    "        X_WINDOW.append(np.sum(img[lb:, r-WIDTH:r] == 255) /\n",
    "                  ((img_height - lb) * WIDTH))\n",
    "        X_WINDOW.append(np.sum(window == 255) / (WIDTH * img_height))\n",
    "        X_WINDOW.append(leftUp(window, img_height))\n",
    "        X_WINDOW.append(rightUp(window, img_height))\n",
    "        X_WINDOW.append(rightDown(window, img_height))\n",
    "        X_WINDOW.append(leftDown(window, img_height))\n",
    "        X_WINDOW.append(vertical(window, img_height))\n",
    "        X_WINDOW.append(horizontal(window, img_height))\n",
    "        window = img[lu:lb, r-WIDTH:r]\n",
    "        X_WINDOW.append(leftUp(window, np.abs(lb-lu)))\n",
    "        X_WINDOW.append(rightUp(window, np.abs(lb-lu)))\n",
    "        X_WINDOW.append(rightDown(window, np.abs(lb-lu)))\n",
    "        X_WINDOW.append(leftDown(window, np.abs(lb-lu)))\n",
    "        X_WINDOW.append(vertical(window, np.abs(lb-lu)))\n",
    "        X_WINDOW.append(horizontal(window, np.abs(lb-lu)))\n",
    "        window = img[lu:lb, r-WIDTH:r]\n",
    "        for w in range(WIDTH):\n",
    "            X_WINDOW.append(np.sum(window[:, w]) / img_height)\n",
    "        contours, _ = cv2.findContours(\n",
    "            window.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        X_WINDOW.append(len(contours))\n",
    "        X_WINDOW.append(np.average(cv2.Canny(window, 50, 200) == 255))\n",
    "        X.append(X_WINDOW)\n",
    "    X[0].append(centers[0][0])\n",
    "    X[0].append(centers[0][1])\n",
    "    for i in range(1, len(centers)):\n",
    "        X[i].append(centers[i][0] - centers[i - 1][0])\n",
    "        X[i].append(centers[i][1] - centers[i - 1][1])\n",
    "    for i in range(0, len(centers)):\n",
    "        X[i].append((centers[i][1] - lb) / img_height)\n",
    "    for inx, vec in enumerate(X):\n",
    "        X[inx] = np.array(vec)\n",
    "    \n",
    "    return np.array(X, dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "\n",
    "def runs_of_ones_list(bits):\n",
    "    return np.array([sum(g) for b, g in groupby(bits) if b], dtype=object)\n",
    "print(runs_of_ones_list(X_train[0][40,:]).shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
=======
>>>>>>> 816822545e758cb8f576cf4ac1469b071af9e9c0
      "(1348, 2)\n"
     ]
    }
   ],
   "source": [
    "data_set = []\n",
    "Y = []\n",
    "for i in range(1, 10):\n",
    "    for filename in os.listdir(\"ACdata_base/\" + str(i)):\n",
    "        img = cv2.imread(os.path.join(\"ACdata_base/\" + str(i),\n",
    "                                      filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            data_set.append(pre_processing(img))\n",
    "            Y.append(i)\n",
<<<<<<< HEAD
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    data_set, Y, test_size=0.2, random_state=85)\n",
    "\n",
=======
    "X_train, X_test, Y_train, Y_test = train_test_split(data_set, Y, test_size=0.2, random_state=42)\n",
>>>>>>> 816822545e758cb8f576cf4ac1469b071af9e9c0
    "\n",
    "# X_validation, X_test, Y_validation, Y_test = train_test_split( X_testValid, Y_testValid, test_size=0.5, random_state=42)\n",
    "# showImage(data_set[2])\n",
    "def getFeatures28(images):\n",
    "    N = 20\n",
    "    WIDTH = 32 \n",
    "    STRID = 8\n",
    "    x_features = []\n",
    "    for i in range(len(images)):\n",
    "            img = images[i]\n",
    "            x_features.append((getImageFeatures(img, WIDTH, int(img.shape[0] / N), STRID, N, baseline_estimatator(img)), Y_train[i]))\n",
    "    return np.asarray(x_features, dtype=object)\n",
    "\n",
    "\n",
    "features28_training = getFeatures28(X_train)\n",
    "\n",
    "print(features28_training.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 98,
=======
   "execution_count": 18,
>>>>>>> 816822545e758cb8f576cf4ac1469b071af9e9c0
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[] for _ in range(9)]\n",
    "for (mat, inx) in features28_training:\n",
    "    for vec in mat:\n",
    "        X[inx - 1].append(vec)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7278, 53)\n",
      "(3409, 53)\n",
      "(4425, 53)\n",
      "(5166, 53)\n",
      "(8073, 53)\n",
      "(6194, 53)\n",
      "(5494, 53)\n",
      "(4258, 53)\n",
      "(6101, 53)\n"
     ]
    }
   ],
>>>>>>> 816822545e758cb8f576cf4ac1469b071af9e9c0
   "source": [
    "X1 = np.array(X[0])\n",
    "X2 = np.array(X[1])\n",
    "X3 = np.array(X[2])\n",
    "X4 = np.array(X[3])\n",
    "X5 = np.array(X[4])\n",
    "X6 = np.array(X[5])\n",
    "X7 = np.array(X[6])\n",
    "X8 = np.array(X[7])\n",
    "X9 = np.array(X[8])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"sample_42_X1.csv\", X[0], delimiter=\",\")\n",
    "# np.savetxt(\"sample_42_X2.csv\", X[1], delimiter=\",\")\n",
    "# np.savetxt(\"sample_42_X3.csv\", X[2], delimiter=\",\")\n",
    "# np.savetxt(\"sample_42_X4.csv\", X[3], delimiter=\",\")\n",
    "# np.savetxt(\"sample_42_X5.csv\", X[4], delimiter=\",\")\n",
    "# np.savetxt(\"sample_42_X6.csv\", X[5], delimiter=\",\")\n",
    "# np.savetxt(\"sample_42_X7.csv\", X[6], delimiter=\",\")\n",
    "# np.savetxt(\"sample_42_X8.csv\", X[7], delimiter=\",\")\n",
    "np.savetxt(\"sample_X1.csv\", X[0], delimiter=\",\")\n",
    "np.savetxt(\"sample_X2.csv\", X[1], delimiter=\",\")\n",
    "np.savetxt(\"sample_X3.csv\", X[2], delimiter=\",\")\n",
    "np.savetxt(\"sample_X4.csv\", X[3], delimiter=\",\")\n",
    "np.savetxt(\"sample_X5.csv\", X[4], delimiter=\",\")\n",
    "np.savetxt(\"sample_X6.csv\", X[5], delimiter=\",\")\n",
    "np.savetxt(\"sample_X7.csv\", X[6], delimiter=\",\")\n",
    "np.savetxt(\"sample_X8.csv\", X[7], delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
=======
   "execution_count": 20,
>>>>>>> 816822545e758cb8f576cf4ac1469b071af9e9c0
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    CLASSES = 9\n",
    "    def __init__(self):\n",
    "        self.models = [GaussianMixture(n_components=6, max_iter=200)\n",
    "                       for _ in range(Model.CLASSES)]\n",
    "    def fit(self, X, y):\n",
    "        self.models[y].fit(X)\n",
    "    def pridect(self, X):\n",
    "        label = None\n",
    "        global_likelihood = float('-inf')\n",
    "        for inx, model in enumerate(self.models):\n",
    "            local_likelihoods = model.score_samples(X)\n",
    "            temp_global_likelihood = sum(local_likelihoods)\n",
    "\n",
    "            if temp_global_likelihood > global_likelihood:\n",
    "                label = inx\n",
    "                global_likelihood = temp_global_likelihood\n",
<<<<<<< HEAD
    "        return label\n",
    "    def save(self):\n",
    "        for i in range(Model.CLASSES):\n",
    "            np.save('gmm_' + str(i) + '_weights', self.models[i].weights_, allow_pickle=False)\n",
    "            np.save('gmm_' + str(i) + '_means', self.models[i].means_, allow_pickle=False)\n",
    "            np.save('gmm_' + str(i) + '_covariances', self.models[i].covariances_, allow_pickle=False)\n",
    "    def reload(self):\n",
    "        self.models = []\n",
    "        for i in range(Model.CLASSES):\n",
    "            means = np.load('gmm_' + str(i) + '_means.npy')\n",
    "            covar = np.load('gmm_' + str(i) + '_covariances.npy')\n",
    "            loaded_gmm = GaussianMixture(\n",
    "                n_components=len(means), covariance_type='full')\n",
    "            loaded_gmm.precisions_cholesky_ = np.linalg.cholesky(np.linalg.inv(covar))\n",
    "            loaded_gmm.weights_ = np.load('gmm_' + str(i) + '_weights.npy')\n",
    "            loaded_gmm.means_ = means\n",
    "            loaded_gmm.covariances_ = covar\n",
    "            self.models.append(loaded_gmm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "M = Model()\n",
    "M.models = None\n",
    "M.reload()\n",
    "print(M.models)"
=======
    "        return label"
>>>>>>> 816822545e758cb8f576cf4ac1469b071af9e9c0
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
=======
   "execution_count": 21,
>>>>>>> 816822545e758cb8f576cf4ac1469b071af9e9c0
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Model()\n",
    "M.fit(X1, 0)\n",
    "M.fit(X2, 1)\n",
    "M.fit(X3, 2)\n",
    "M.fit(X4, 3)\n",
    "M.fit(X5, 4)\n",
    "M.fit(X6, 5)\n",
    "M.fit(X7, 6)\n",
    "M.fit(X8, 7)\n",
<<<<<<< HEAD
    "M.fit(X9, 8)\n",
    "\n"
=======
    "M.fit(X9, 8)"
>>>>>>> 816822545e758cb8f576cf4ac1469b071af9e9c0
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 44,
=======
   "execution_count": 22,
>>>>>>> 816822545e758cb8f576cf4ac1469b071af9e9c0
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "img = X_test[3]\n",
    "X_t = getImageFeatures(img, 32, int(img.shape[0] / 20), 16, 20, baseline_estimatator(img))\n",
    "    \n",
    "print(Y_test[3])\n",
    "print(M.pridect(X_t) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 95,
=======
   "execution_count": 23,
>>>>>>> 816822545e758cb8f576cf4ac1469b071af9e9c0
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "97.55192878338279\n"
=======
      "97.99703264094956\n"
>>>>>>> 816822545e758cb8f576cf4ac1469b071af9e9c0
     ]
    }
   ],
   "source": [
    "ac = 0\n",
    "for inx, img in enumerate(X_train):\n",
    "    X_t = getImageFeatures(img, 32, int(\n",
    "        img.shape[0] / 20), 16, 20, baseline_estimatator(img))\n",
    "    if M.pridect(X_t) + 1 == Y_train[inx]:\n",
    "        ac +=1\n",
    "print(ac/len(Y_train) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 112,
=======
   "execution_count": 24,
>>>>>>> 816822545e758cb8f576cf4ac1469b071af9e9c0
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "95.25222551928783\n"
=======
      "92.87833827893175\n"
>>>>>>> 816822545e758cb8f576cf4ac1469b071af9e9c0
     ]
    }
   ],
   "source": [
    "ac = 0\n",
    "for inx, img in enumerate(X_test):\n",
    "    X_t = getImageFeatures(img, 32, int(\n",
    "        img.shape[0] / 20), 16, 20, baseline_estimatator(img))\n",
    "    if M.pridect(X_t) + 1 == Y_test[inx]:\n",
    "        ac += 1\n",
    "print(ac/len(Y_test) * 100)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af19850de543c87aa9c5433cdfdc668182c4fce690f4a520383c35fe24f2761b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
