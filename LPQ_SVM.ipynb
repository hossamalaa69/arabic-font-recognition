{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from __future__ import division\n",
    "from scipy.signal import convolve2d\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBorderColor(img):\n",
    "    border = np.asarray(img[0,:])\n",
    "    border = np.concatenate((border, np.asarray(img[-1, :])))\n",
    "    border = np.concatenate((border, np.asarray(img[:, 0])))\n",
    "    border = np.concatenate((border, np.asarray(img[:, -1])))\n",
    "    return np.bincount(border).argmax()\n",
    "\n",
    "\n",
    "def pre_processing(img):\n",
    "    _, img_binarized = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)    \n",
    "    if(getBorderColor(img_binarized) != 0):\n",
    "        img_binarized = cv2.bitwise_not(img_binarized) \n",
    "    \n",
    "    kernel = np.ones((30,30), np.uint8)\n",
    "    img_dilation = cv2.dilate(img_binarized, kernel, iterations=1)\n",
    "    cnts = cv2.findContours(img_dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    cntsSorted = sorted(cnts, key=lambda x: cv2.contourArea(x), reverse=True)\n",
    "    (x,y,w,h) = cv2.boundingRect(cntsSorted[0])\n",
    "    return img_binarized[y:y+h, x:x+w]    \n",
    "\n",
    "def showImage(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = []\n",
    "Y = []\n",
    "for i in range(1, 10):\n",
    "    for filename in os.listdir(\"ACdata_base/\" + str(i)):\n",
    "        img = cv2.imread(os.path.join(\"ACdata_base/\" + str(i),filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            data_set.append(pre_processing(img))\n",
    "            Y.append(i-1)\n",
    "            \n",
    "#X_validation, X_test, Y_validation, Y_test = train_test_split(X_testValid, Y_testValid, test_size=0.5, random_state=42)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_testValid, Y_train, Y_testValid = train_test_split(data_set, Y, test_size=0.2, random_state=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique, counts = np.unique(np.array(Y_train), return_counts=True)\n",
    "# print(np.asarray((unique, counts)).T)\n",
    "\n",
    "# unique, counts = np.unique(np.array(Y_testValid), return_counts=True)\n",
    "# print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1348\n",
      "1348\n",
      "337\n",
      "337\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(Y_train))\n",
    "print(len(X_testValid))\n",
    "print(len(Y_testValid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lpq(img, winSize=3, freqestim=1, mode='nh'):\n",
    "    \n",
    "    rho=0.90\n",
    "\n",
    "    STFTalpha=1/winSize  # alpha in STFT approaches (for Gaussian derivative alpha=1)\n",
    "    sigmaS=(winSize-1)/4 # Sigma for STFT Gaussian window (applied if freqestim==2)\n",
    "    sigmaA=8/(winSize-1) # Sigma for Gaussian derivative quadrature filters (applied if freqestim==3)\n",
    "\n",
    "    convmode='valid' # Compute descriptor responses only on part that have full neigborhood. Use 'same' if all pixels are included (extrapolates np.image with zeros).\n",
    "\n",
    "    img=np.float64(img) # Convert np.image to double\n",
    "    r=(winSize-1)/2 # Get radius from window size\n",
    "    x=np.arange(-r,r+1)[np.newaxis] # Form spatial coordinates in window\n",
    "\n",
    "    if freqestim==1:  #  STFT uniform window\n",
    "        #  Basic STFT filters\n",
    "        w0=np.ones_like(x)\n",
    "        w1=np.exp(-2*np.pi*x*STFTalpha*1j)\n",
    "        w2=np.conj(w1)\n",
    "\n",
    "    ## Run filters to compute the frequency response in the four points. Store np.real and np.imaginary parts separately\n",
    "    # Run first filter\n",
    "    filterResp1=convolve2d(convolve2d(img,w0.T,convmode),w1,convmode)\n",
    "    filterResp2=convolve2d(convolve2d(img,w1.T,convmode),w0,convmode)\n",
    "    filterResp3=convolve2d(convolve2d(img,w1.T,convmode),w1,convmode)\n",
    "    filterResp4=convolve2d(convolve2d(img,w1.T,convmode),w2,convmode)\n",
    "\n",
    "    # Initilize frequency domain matrix for four frequency coordinates (np.real and np.imaginary parts for each frequency).\n",
    "    freqResp=np.dstack([filterResp1.real, filterResp1.imag,\n",
    "                        filterResp2.real, filterResp2.imag,\n",
    "                        filterResp3.real, filterResp3.imag,\n",
    "                        filterResp4.real, filterResp4.imag])\n",
    "\n",
    "    ## Perform quantization and compute LPQ codewords\n",
    "    inds = np.arange(freqResp.shape[2])[np.newaxis,np.newaxis,:]\n",
    "    LPQdesc=((freqResp>0)*(2**inds)).sum(2)\n",
    "\n",
    "    ## Switch format to uint8 if LPQ code np.image is required as output\n",
    "    if mode=='im':\n",
    "        LPQdesc=np.uint8(LPQdesc)\n",
    "\n",
    "    ## Histogram if needed\n",
    "    if mode=='nh' or mode=='h':\n",
    "        LPQdesc=np.histogram(LPQdesc.flatten(),range(256))[0]\n",
    "\n",
    "    ## Normalize histogram if needed\n",
    "    if mode=='nh':\n",
    "        LPQdesc=LPQdesc/LPQdesc.sum()\n",
    "    \n",
    "    return LPQdesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(img):\n",
    "    return lpq(img)\n",
    "\n",
    "def getFeaturesList(images):\n",
    "   features = []\n",
    "   for i in range(len(images)):\n",
    "        features.append(getFeatures(images[i]))\n",
    "   return np.asarray(features)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1348, 255)\n",
      "(337, 255)\n"
     ]
    }
   ],
   "source": [
    "features_train = getFeaturesList(X_train)\n",
    "features_test = getFeaturesList(X_testValid)\n",
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "\n",
    "#print(features_lpq)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(gamma='auto'))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(features_train)\n",
    "y = np.array(Y_train)\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.54896142433235\n"
     ]
    }
   ],
   "source": [
    "y_pred = (clf.predict(features_test))\n",
    "#print(Y_validation)\n",
    "acc = np.mean(y_pred == Y_testValid) * 100\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af19850de543c87aa9c5433cdfdc668182c4fce690f4a520383c35fe24f2761b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
